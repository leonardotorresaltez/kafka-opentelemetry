server.port: 8090
server.address: 0.0.0.0

logging:
  level:
    root: INFO

spring:
  kafka:
    bootstrap-servers: broker:29092
    streams:
      application-id: "streams.custom-metrics-demo.v1"
      bootstrap-servers: "broker:29092"
      properties:
        state.dir: state-dir
        metrics.recording.level: "TRACE"
        retries: 3
    properties:
      schema.registry.url: http://schema-registry:8081
      auto.offset.reset: latest
      auto.register.schemas: true
      default.deserialization.exception.handler: org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
      default.production.exception.handler: org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
      default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
      default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde

app:
  properties:
    bookTopic: bookTopic
    categoryTopic: categoryTopic
    stateStoreCategoryTopic: stateStoreCategoryTopic
    bookEnrichedTopic: bookEnrichedTopic  
  kafka.custom:
    staticMembership: false
    maxPollRecords: 500
    standByReplicas: 0
    sessionTimeOut: 30000
    heartbeatInterval: 3000
    linger: 0
    requestTimeout: 60000
    numThreads: 3
    logAdditionalRetentionTime: 86400000
    cacheMaxBytesBuffering: 0
    changeLogConfig:
      cleanup.policy: compact,delete
      segment.bytes: 536870912 #500mb
      segment.ms: 86400000 #1 dia
      min.cleanable.dirty.ratio: 0.01 # 1%

management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-components: always
      show-details: always
      probes:
        enabled: true
